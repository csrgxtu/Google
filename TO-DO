28/Feb/2014
get myself familiar with apache's httpclient, and implement a class
that is responsible to download a url link.

12/Mar/2014
well, it is wired, i remember that last time i tested the mongodb
in this project, and synched with the github, but this time, when
i check, there is no such thing. well, whatever, I need to create
database and store the visited and unvisited table in the mongo
database.

14/Mar/2014
focus on how to solve the abs urls problems in RetrieveHref.java

15/Mar/2014
focus on solving the variaty url problems, i.e, i want url is sth
standard like "http://blogxtu.zapto.org/", if the url isnt a url
or is empty or point to a big large file, it needs to be filted.
also, I want to  implement a functionality to crawl only a website,
just like what Nutch does.

17/Mar/2014
Well, the ShadowWalker can work, but it didn't perfect, eat up 40
percent of the CPU and 20 percent Memory. and sometimes stuck with
an URL, long time without responding, it seems that the set
connection timeout didnt do the work, well, httpclient is such a
basterd, i am gonna to use hard way to limit the connection time,
and write a domain filter to restrict the url into only a domain.
